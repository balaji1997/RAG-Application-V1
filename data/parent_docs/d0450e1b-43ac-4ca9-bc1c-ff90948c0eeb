{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "High-level summary of the AI Act\n\n27 Feb, 2024\n\nUpdated on 30 May in accordance with the Corrigendum version of the AI Act.\n\nIn this article we provide you with a high-level summary of the AI Act, selecting the parts which are most likely to be relevant to you regardless of who you are. We provide links to the original document where relevant so that you can always reference the Act text.\n\nTo explore the full text of the AI Act yourself, use our AI Act Explorer. Alternatively, if you want to know which parts of the text are most relevant to you, use our Compliance Checker. \n\nFour-point summary\n\nThe AI Act classifies AI according to its risk:\n\nUnacceptable risk is prohibited (e.g. social scoring systems and manipulative AI).\n\nMost of the text addresses high-risk AI systems, which are regulated.\n\nA smaller section handles limited risk AI systems, subject to lighter transparency obligations: developers and deployers must ensure that end-users are aware that they are interacting with AI (chatbots and deepfakes).\n\nMinimal risk is unregulated (including the majority of AI applications currently available on the EU single market, such as AI enabled video games and spam filters \u2013 at least in 2021; this is changing with generative AI).\n\nThe majority of obligations fall on providers (developers) of high-risk AI systems.\n\nThose that intend to place on the market or put into service high-risk AI systems in the EU, regardless of whether they are based in the EU or a third country.", "metadata": {"source": "uploaded_docs\\EU AI Act Doc.docx", "doc_id": "85f9ade0-4eb1-4a79-a87f-202bfa94e016"}, "type": "Document"}}