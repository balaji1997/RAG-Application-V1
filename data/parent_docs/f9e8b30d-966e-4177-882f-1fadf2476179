{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "And also third country providers where the high risk AI system\u2019s output is used in the EU.\n\nUsers are natural or legal persons that deploy an AI system in a professional capacity, not affected end-users.\n\nUsers (deployers) of high-risk AI systems have some obligations, though less than providers (developers).\n\nThis applies to users located in the EU, and third country users where the AI system\u2019s output is used in the EU.\n\nGeneral purpose AI (GPAI):\n\nAll GPAI model providers must provide technical documentation, instructions for use, comply with the Copyright Directive, and publish a summary about the content used for training.\n\nFree and open licence GPAI model providers only need to comply with copyright and publish the training data summary, unless they present a systemic risk.\n\nAll providers of GPAI models that present a systemic risk \u2013 open or closed \u2013 must also conduct model evaluations, adversarial testing, track and report serious incidents and ensure cybersecurity protections.\n\nProhibited AI systems (Chapter II, Art. 5)\n\nThe following types of AI system are \u2018Prohibited\u2019 according to the AI Act.\n\nAI systems:\n\ndeploying subliminal, manipulative, or deceptive techniques to distort behaviour and impair informed decision-making, causing significant harm.\n\nexploiting vulnerabilities related to age, disability, or socio-economic circumstances to distort behaviour, causing significant harm.", "metadata": {"source": "uploaded_docs\\EU AI Act Doc.docx", "doc_id": "db37fc09-4b70-4ba7-b3e1-63005ba07907"}, "type": "Document"}}